{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f79afe-d8f6-4b6c-b2db-089fbcd0a61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T09:06:04.321246300Z",
     "start_time": "2024-07-22T09:06:03.492781500Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from tifffile import imread, imwrite, TiffFile\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from wf_utils import *\n",
    "from wfield_utils import *\n",
    "# from multi_load_images import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851050c4b56f40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T20:09:25.202091Z",
     "start_time": "2024-05-20T20:09:25.140742200Z"
    }
   },
   "outputs": [],
   "source": [
    "### Set the file path\n",
    "\n",
    "# path_0: including one-day recording files\n",
    "# path_1: including every stimuli\n",
    "path_0 = r\"/home/lzx/data/WF_WRX/P42/20240726/DOM\"\n",
    "path_1_ = os.listdir(path_0)\n",
    "# 筛选出文件夹\n",
    "path_1 = [folder for folder in path_1_ if os.path.isdir(pjoin(path_0, folder))]\n",
    "path_all = []\n",
    "for path in path_1:\n",
    "    path_all.append(pjoin(path_0, path))\n",
    "\n",
    "print('All the file path:\\n'+str(path_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a1322-209e-48f6-a216-f060ab3c6fcd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### re-organize files\n",
    "\n",
    "for path in path_all:\n",
    "    if not os.path.exists(pjoin(path, 'raw')):\n",
    "        os.mkdir(pjoin(path, 'raw'))\n",
    "    if not os.path.exists(pjoin(path, 'process/')):\n",
    "        os.mkdir(pjoin(path, 'process/'))\n",
    "        \n",
    "for path in path_all:\n",
    "    files = glob(pjoin(path, '202?????-??????*'))\n",
    "    for file in files:\n",
    "        shutil.move(file, pjoin(path, 'raw', os.path.basename(file)))\n",
    "        print('moving',file)\n",
    "\n",
    "print('Moving raw data folders all finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8491c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate 2-channel tif stack\n",
    "\n",
    "def organize_tif(folder_path):\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    if os.path.exists(folder_path+'.tif'):\n",
    "        print('importing {}.tif'.format(folder_path))\n",
    "        image_stack = imread(folder_path+'.tif')\n",
    "        print('finish importing {}.tif'.format(folder_path))\n",
    "    else:\n",
    "        image_path_ls = glob(pjoin(folder_path, '*.tif'))\n",
    "        image_path_ls = sorted(image_path_ls, key = filename2int) # 确保图像帧按顺序排列\n",
    "        image_stack = [imread(tiff) for tiff in log_progress(image_path_ls, name=folder_name)]  # 将多帧tif堆叠成数组\n",
    "        # image_stack = multi_load_images(image_path_ls, n_thread=20)\n",
    "    # rotated_images = [cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE) for frame in image_stack]   # 顺时针旋转图像90度\n",
    "    # 计算并保存均值数据\n",
    "    mean_values = [np.mean(frame) for frame in image_stack]\n",
    "    output_value = pjoin(processPath, folder_name + \"-Values.csv\")\n",
    "    np.savetxt(output_value, mean_values, delimiter=\",\")\n",
    "    \n",
    "    return np.array(image_stack)\n",
    "\n",
    "\n",
    "for path in path_all:\n",
    "    print(\"Path: \"+ path)\n",
    "    rawPath = pjoin(path, \"raw\")\n",
    "    processPath = pjoin(path, \"process\")\n",
    "    # 列出experiments\n",
    "    items = glob(pjoin(rawPath, '202?????-??????-4*'))\n",
    "    experiments = list(set([os.path.basename(item)[:15] for item in items]))\n",
    "    print(\"experiments:\")\n",
    "    print(experiments)\n",
    "    \n",
    "    # 遍历每个experiment，merge channel\n",
    "    for experiment in experiments:\n",
    "        os.makedirs(pjoin(processPath, experiment+\"-wfield\"), exist_ok=True)\n",
    "        mergePath = pjoin(processPath, experiment+\"-wfield\")\n",
    "        merge_file = pjoin(mergePath, experiment+\"-merged.tif\")\n",
    "        if not os.path.exists(merge_file):\n",
    "            tif_405 = organize_tif(pjoin(rawPath, experiment + \"-405\"))\n",
    "            tif_470 = organize_tif(pjoin(rawPath, experiment + \"-470\"))\n",
    "            # 检查两个通道的深度是否一致\n",
    "            if tif_405.shape[0] != tif_470.shape[0]:\n",
    "                n_frames = min(tif_405.shape[0], tif_470.shape[0])\n",
    "                tif_405 = tif_405[:n_frames]\n",
    "                tif_470 = tif_470[:n_frames]\n",
    "            # 将Tiff stack的数据从三维变成四维，不同通道使用第二维区分\n",
    "            merged_tif = np.concatenate((tif_470[:, np.newaxis], tif_405[:, np.newaxis]), axis=1)\n",
    "            # 将合并后的图像保存为一个2通道Tiff图像\n",
    "            imwrite(merge_file, merged_tif, imagej=True, bigtiff=True)\n",
    "                        \n",
    "        else: print(\"merged \"+experiment+\" has existed\")\n",
    "        plotFluor(path, experiment)\n",
    "        \n",
    "    print(\"\\nfinished \"+ path+\"\\n\\n\")\n",
    "    \n",
    "print(\"All merging finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e88f4",
   "metadata": {},
   "source": [
    "### ********************************************************************************************************************\n",
    "### 从这里开始用wfield软件做运动矫正、奇异值分解、血流动力学矫正。以下必须用wfield环境！！！\n",
    "### ********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383dd27-80c5-4641-b7ba-c491a22d0e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T20:09:36.182469700Z",
     "start_time": "2024-05-20T20:09:34.596810900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try wfield\n",
    "\n",
    "! wfield -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7b4cc-64a4-4bfb-882a-ec26ea09fd16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T20:09:38.015438100Z",
     "start_time": "2024-05-20T20:09:37.841673800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 列出所有已经合并通道的tiff的路径\n",
    "\n",
    "path_wfield_all = glob(pjoin(path_0, '*/process/*-wfield'))\n",
    "print('All the wfield-path:\\n'+\"\\n\".join(path_wfield_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4760a4f-0180-477f-8497-199840057680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_delete = glob(pjoin(path_0, '*/process/*-wfield/*.bin'))\n",
    "# path_delete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481b4a6-112b-4543-aee1-3f1a659924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_delete in path_delete:\n",
    "#     try:\n",
    "#         os.remove(file_delete)\n",
    "#         print(f\"Deleted: {file_delete}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting {file_delete}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807cfdfe-7a04-4646-baef-0cb43fdeb82a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### 生成trial_onsets.npy\n",
    "\n",
    "n_movie_rep = 5\n",
    "\n",
    "for path_wfield in path_wfield_all:\n",
    "    \n",
    "    experiment = os.path.basename(path_wfield)[:15]\n",
    "    rawPath = pjoin(path_wfield,'../../raw')\n",
    "    merge_file = pjoin(path_wfield, experiment+\"-merged.tif\")\n",
    "    n_frames = len(TiffFile(merge_file).pages)//2\n",
    "\n",
    "    if os.path.exists(pjoin(rawPath, experiment + \".csv\")):\n",
    "        # generate trial_onsets.npy\n",
    "        # trial_onsets.npy is a Nx3 array. The columns are: trial number, onset of the trial (frame index), offset of the trial.\n",
    "        if not os.path.exists(pjoin(path_wfield, 'trials.csv')):\n",
    "            stimfile = pd.read_csv(pjoin(rawPath, experiment + \".csv\"), header=None).values\n",
    "            stim_delay = pd.read_csv(pjoin(rawPath, experiment + \"-470Timestamp.csv\"), header=None).values\n",
    "            stim_delay = int(stim_delay[0]/10)\n",
    "            \n",
    "            stim = np.zeros(n_frames)\n",
    "            for i in range(n_frames):\n",
    "                stim[i] = stimfile[(i * 10 + stim_delay), 0]\n",
    "            single_0_indices = np.where((np.diff(np.append(stim, 0)) == 1) & (np.diff(stim, prepend=0) == -1))[0]\n",
    "            single_1_indices = np.where((np.diff(np.append(stim, 0)) == -1) & (np.diff(stim, prepend=0) == 1))[0]\n",
    "            stim[single_1_indices] = 0\n",
    "            stim[single_0_indices] = 1\n",
    "            \n",
    "            onset = np.where(np.diff(stim) == 1)[0] + 1\n",
    "            offset = np.where(np.diff(stim) == -1)[0] + 1\n",
    "            trials_csv = np.stack((np.arange(len(onset)), onset, offset, offset-onset), axis=1)  # 这个用来自己检查一下以及自己后续分析\n",
    "            np.savetxt(pjoin(path_wfield, \"trials.csv\"), trials_csv, delimiter=\",\")\n",
    "            print(\"generate trials.csv of \"+experiment)\n",
    "            \n",
    "            if 'retinotopy' or 'checkerboard-bar' in path_wfield:\n",
    "                trial_onsets = np.stack((np.arange(len(onset)), onset - 30, offset), axis=1)  # 这个文件给wfield软件做SVD用\n",
    "                np.save(pjoin(path_wfield, 'trial_onsets.npy'), trial_onsets)\n",
    "            \n",
    "            elif 'natural-movie' in path_wfield:\n",
    "                n_movie = len(onset)//n_movie_rep\n",
    "                trial_onsets = np.empty((n_movie,3))\n",
    "                for i in range(n_movie):\n",
    "                    trial_onsets[i] = [i, onset[i*n_movie_rep] - 100, offset[i*n_movie_rep]]\n",
    "                np.save(pjoin(path_wfield, 'trial_onsets.npy'), trial_onsets)   # 这个文件给wfield软件做SVD用\n",
    "            # elif 'speed' in path_wfield:\n",
    "            #     trial_onsets = [0, onset[0] - 100, offset[0]]\n",
    "            #     np.save(pjoin(path_wfield, 'trial_onsets.npy'), trial_onsets)   # 这个文件给wfield软件做SVD用\n",
    "        else: print(\"trials.csv of \"+experiment+\" has existed\")\n",
    "\n",
    "    else: print(experiment, 'without stim-file, skip')\n",
    "            \n",
    "print(\"\\nAll generation of trials-file finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875325d-b677-4ee3-a4a6-9283a7f64fc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T07:39:36.323895Z",
     "start_time": "2024-07-22T07:39:35.960322400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 用wfield进行Motion correction, single value decomposition, hemodynamic correction。\n",
    "\n",
    "for path_wfield in path_wfield_all:\n",
    "    if len(glob(pjoin(path_wfield, '*-merged.tif'))) == 0:\n",
    "        print(path_wfield,\"can't find merged tiff file！\\n\")\n",
    "    elif len(glob(pjoin(path_wfield, '*-merged.tif'))) > 1:\n",
    "        print(path_wfield,\"exist multiple merged tiff file！\\n\")\n",
    "    elif os.path.exists(pjoin(path_wfield, 'SVTcorr.npy')):\n",
    "        print(path_wfield,'analysis has been finished！\\n')\n",
    "    else:\n",
    "        print('Start analyze',path_wfield)\n",
    "        if 'natural-movie' or 'speed' in path_wfield:\n",
    "            nbaseline_frames = 100\n",
    "        else: \n",
    "            nbaseline_frames = 30\n",
    "        command = \"wfield preprocess --nchannels 2 --nbaseline-frames {} --functional-channel 0 --fs 10 -o {} {}\".format(nbaseline_frames,path_wfield,path_wfield)\n",
    "        logfile = pjoin(path_wfield, 'log.txt')\n",
    "        with open(logfile, \"w\") as log:\n",
    "            result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "            log.write(result.stdout)\n",
    "        if result.returncode == 0:\n",
    "            print('Finish analyzing',path_wfield,'\\n')\n",
    "        else:\n",
    "            print('！！！Error occured when analyzing',path_wfield,'\\n')\n",
    "        \n",
    "print('\\nMotion correction, single value decomposition, hemodynamic correction. All finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2c260-a6fd-4127-9e67-9f8f96c403ee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 重构矫正后图像\n",
    "\n",
    "export_corr_tif = False\n",
    "\n",
    "if export_corr_tif is True:\n",
    "    for path_wfield in path_wfield_all:\n",
    "        print('\\npath', path_wfield)\n",
    "        filename = os.path.basename(glob(pjoin(path_wfield, '*-merged.tif'))[0])[:16]\n",
    "        if not (os.path.exists(pjoin(path_wfield, filename+\"SVD_corr.tif\")) or os.path.exists(pjoin(path_wfield, filename+\"SVD_corr_uint16.tif\")) or os.path.exists(pjoin(path_wfield, filename+\"hemo-corr.tif\"))):\n",
    "            svd2tif(path_wfield, name=filename, uint16=False, corr470=True)\n",
    "        else:\n",
    "            print('reconstruction has been finished！')\n",
    "        \n",
    "    print('\\n\\nAll image reconstruction finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379bd015-87d9-46f0-b5da-64110cb4c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wfield_utils import *\n",
    "\n",
    "for path_wfield in path_wfield_all:\n",
    "    if 'retinotopy' or 'checkerboard-bar' in path_wfield:\n",
    "        phasemap(path_wfield, nrepeats=10, post_trial=3, export_ave_tif=False, export_raw_tif=False, \n",
    "         plot_snr=True, plot_phasemasp=True, export_phase=True)\n",
    "        phasemap(path_wfield, nrepeats=10, post_trial=0, export_ave_tif=True, export_raw_tif=True, \n",
    "         plot_snr=False, plot_phasemasp=False, export_phase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffdd453729f098",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
