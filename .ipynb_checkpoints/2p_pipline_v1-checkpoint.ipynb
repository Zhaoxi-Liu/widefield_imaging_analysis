{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "741b0e1f-5504-4256-8369-1549c963ba95",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e459dad-93fe-4ef6-9b9f-08efb3e48584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob, gc\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "para = {'distance':170, #mm\n",
    "           'azimuth':95, #deg\n",
    "           'elevation':25, #deg\n",
    "           'width':527, #mm\n",
    "           'height':294, #mm\n",
    "           'visual_center': (95,25),\n",
    "           'width_pix':1920, # in pixel\n",
    "           'height_pix':1080, # in pixel\n",
    "           'sampling_rate': 1/0.100422669,\n",
    "           'micrometer_per_pixel': 1.08584274605766,\n",
    "           'imag_size_pixel':np.array([512,512]), # in pixel\n",
    "        \n",
    "        }\n",
    "para['imag_size'] = para['imag_size_pixel']*para['micrometer_per_pixel'] # in micrometer\n",
    "\n",
    "\n",
    "\n",
    "mice_id = 'C52'\n",
    "exp_date = '20230923'# experiment date\n",
    "\n",
    "date_experiment = datetime.datetime.strptime(exp_date, '%Y%m%d')\n",
    "\n",
    "date = datetime.datetime.strptime('20230806', '%Y%m%d') \n",
    "\n",
    "stimulus_ls = ['1_RF4_6', '2_MovingBar', '3_SalienceGrating_1','4_SalienceGrating_2','5_SalienceGrating_3'\n",
    "                     , '6_SalienceMovingDots_1','7_SalienceMovingDots_2','8_SalienceMovingDots_3','9_MovingDots']\n",
    "stimulus_num = len(stimulus_ls)\n",
    "\n",
    "date = datetime.datetime.strptime('20230806', '%Y%m%d') \n",
    "if  date_experiment<date:\n",
    "    para['speed_mm'] = 139 #mm/sec\n",
    "    para['speed_deg'] = 44.5 #deg/sec\n",
    "else:\n",
    "    para['speed_mm'] = 158.5 #mm/sec\n",
    "    para['speed_deg'] = 50 #deg/sec\n",
    "plane_total_ls = [1,2,3]\n",
    "plane_num = len(plane_total_ls)\n",
    "channel_total_ls = [1, 2]\n",
    "\n",
    "# parent_folder = '/Volumes/Data_2p/saliency_map/' #this may need to be changed across different computers\n",
    "parent_folder = 'Z:/saliency_map/'\n",
    "\n",
    "folder_2p_path = parent_folder + \"two-photon/\" + mice_id + '/' + exp_date\n",
    "folder_behavioral_path = parent_folder + \"behavioral_data/\" + mice_id + '/' + exp_date\n",
    "save_folder_ls = ['analysis','corrected','ROIs','tiff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3c7de-454b-4345-a851-a409254377c0",
   "metadata": {},
   "source": [
    "### Step 0: Write meta information to hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0ca06-2830-4069-b038-26b7304ae405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_utils import get_stim_time\n",
    "from other_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime, os\n",
    "\n",
    "z_focus = {'C6':{'20230705': np.array([70, 120, 170]),\n",
    "               '20230707': np.array([90, 140, 190]),\n",
    "               '20230723': np.array([100, 130, 160])},\n",
    "            'C8':{'20230706':np.array([70, 120, 170]),\n",
    "               '20230708': np.array([90, 140, 190]),\n",
    "               '20230723': np.array([125, 150, 175])},\n",
    "            'C49':{'20230919':np.array([30, 80, 130])},\n",
    "            'C50':{'20230921':np.array([50, 100, 150])},\n",
    "            'C51':{'20230922':np.array([50, 100, 150])},\n",
    "            'C52':{'20230923':np.array([60, 110, 160])},\n",
    "               }\n",
    "\n",
    "for stimulus_sel in range(1, 1+stimulus_num):  # \n",
    "\n",
    "    stim_folder = glob.glob(folder_2p_path + '/raw/TSeries-*' + '{}'.format(stimulus_sel))[0]\n",
    "    trigger_file = glob.glob(stim_folder + '/*.csv')[0]\n",
    "    print(trigger_file)\n",
    "    imaging_parameters, stim_parameters = meta_data(exp_date=exp_date, stim_num=stimulus_sel, trigger_file=trigger_file,folder_path=parent_folder)\n",
    "\n",
    "    # write data to h5 file\n",
    "    imaging_dict = {}\n",
    "    for key in imaging_parameters.keys():\n",
    "        imaging_dict[key] = np.array(imaging_parameters[key])\n",
    "\n",
    "    stim_dict = {}\n",
    "    for key in stim_parameters.keys():\n",
    "        stim_dict[key] = np.array(stim_parameters[key])\n",
    "\n",
    "    data_dict = {\n",
    "        'imaging':imaging_dict,\n",
    "        'vs':stim_dict}\n",
    "\n",
    "    for plane in plane_total_ls:\n",
    "        h5_name = '{}_{}_plane_{}_stimuli_{}.hdf5'.format(mice_id, exp_date, plane, stimulus_sel)\n",
    "        print(h5_name)\n",
    "        h5_path = os.path.join(folder_2p_path, 'Plane{}'.format(plane), 'Analysis', stimulus_ls[stimulus_sel-1], h5_name)\n",
    "        print(h5_path)\n",
    "        depth = z_focus[mice_id][exp_date][plane-1]\n",
    "        data_dict['imaging']['depth'] = np.array(depth)\n",
    "        h5py_write(file_path=h5_path, data_dict=data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9eec16-78f4-4b87-ab04-e7c01293a9b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: convert acquired calcium images from 2p to videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bdf2f-bcf5-46a0-9f16-f1e939aa2648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from convert_utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c24f0-d680-4c9f-8fc0-2e412544bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the folders with designed folder_tree\n",
    "folder_tree (folder_path=folder_2p_path, plane_total_ls=plane_total_ls, sub_folder_ls =save_folder_ls,stimulus_total_ls=stimulus_ls)\n",
    "# convert single images to movie\n",
    "p_offset = False # determine need offset or not\n",
    "phase_offset = 2 #pixels\n",
    "for plane in plane_total_ls:\n",
    "    for channel in channel_total_ls:\n",
    "        tseries_integrate(folder_2p_path, plane_num=plane, channel=channel, stimulus=True, stimuli='001', p_offset=p_offset, phase_offset=phase_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0a580-eaba-4d2e-a600-cc51b0d75528",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: perform motion correction to remove artifacts caused by animal movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2756866-df71-4e24-a500-f9ecb4656c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from motion_correction_utils import *\n",
    "from other_utils import *\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf786d0-6162-444f-8fe5-472e6d4879b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the [all_files=True], you can use the 001-Ch1 tamplate to share the shift to all stimulus  \n",
    "# If the [shift_share=True], the [fname file(Channel1)] will share to shifts to the [fname_1 file(Channel2)]\n",
    "# If the memory error appears, restarting the computer, setting the [std=False], or increasing the virtual memory capacity may be a useful way to solve this problem. \n",
    "\n",
    "# motion correction\n",
    "shifts_dict_ls = []\n",
    "template_dict_ls = []\n",
    "for plane in plane_total_ls:\n",
    "    shifts_dict, template_dict = CaImAn_func(folder_2p_path,mice_id,exp_date, plane_num=plane,shift_share=True,all_files=True,std=True,plot_shift_=True)\n",
    "    shifts_dict_ls.append(shifts_dict)\n",
    "    template_dict_ls.append(template_dict)\n",
    "    gc.collect()\n",
    "for i in range(len(plane_total_ls)):\n",
    "    shifts_dict = shifts_dict_ls[i]\n",
    "    template_dict = template_dict_ls[i]\n",
    "    plane = plane_total_ls[i]\n",
    "    # save the template and per-stimuli shifts to hdf5 \n",
    "    for stimuli_name in shifts_dict.keys():\n",
    "        stimuli_num = int(stimuli_name.split('_')[-1])\n",
    "        sub_folder_name = stimulus_ls [stimuli_num-1]\n",
    "        print(shifts_dict[stimuli_name].shape)\n",
    "        dict_mc = {'raw': {'mc': shifts_dict[stimuli_name]}} #the 'raw' is the group name, the 'mc' is the dataset name\n",
    "        dict_mc = {'raw': {'template': template_dict['template']}} # save the 'total_template_rig' to each hdf5 files\n",
    "        fpath_hdf5 = parent_folder_path + \"two-photon/{}/{}/plane{}/analysis/{}/{}_{}_plane_{}_stimuli_{}.hdf5\".format(mice_id, exp_date, plane, sub_folder_name, mice_id,  exp_date, plane, str(stimuli_num))\n",
    "        h5py_write(file_path=fpath_hdf5, data_dict=dict_mc)\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcbff71-0be2-4254-8e8d-2283a7be20f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: extract neuronal signals from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e385cf9-1c7d-4f7b-b786-deec532e1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_rois_utils import *\n",
    "from other_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6272b9-e6ae-4e04-91b0-711387815bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plane in plane_total_ls:\n",
    "    rois_folder_path = folder_2p_path +  \"/plane{}/ROIs\".format(plane)\n",
    "    print('rois_folder_path: ', rois_folder_path)\n",
    "    # stimuli_list = [0,1,2,3,4,5,6,7,8]\n",
    "    for stim in range(1,stimulus_num+1): \n",
    "        # paths\n",
    "        tiff_path = glob.glob(folder_2p_path + '/plane{}/corrected/TSeries*00{}_plane*Ch2*.tif'.format(str(plane), str(stim)))[0]\n",
    "        h5_path = folder_2p_path + '/plane{}/analysis/{}/{}_{}_plane_{}_stimuli_{}.hdf5'.format(str(plane), stimulus_ls[stim-1], mice_id, exp_date, plane, stim)\n",
    "        print(\"tiff_read_path: \", tiff_path)\n",
    "        print('saved_hdf5_path: ', h5_path)\n",
    "        \n",
    "        # rois extraction\n",
    "        rois_dict = extract_rois(tiff_path,rois_folder_path,surr_r=int(20/para['micrometer_per_pixel']),f_surr=0.7,win=int(15*para['sampling_rate']),plot_rois=True)\n",
    "        \n",
    "        # save the extracted rois to hdf5 \n",
    "        h5py_write(h5_path, {'rois':rois_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63087ee-4685-4175-9235-9149f2bcba5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 4: analyze animal movement and pupuil changes, and align them to calcium signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d14b1e-ca9b-4b73-9643-90ceea4219ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from behavior_utils import *\n",
    "from other_utils import *\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578385b-4ad9-4c1c-97ed-6d0a66cc59d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# analyze speed\n",
    "speed_dict = speed_extract(folder_behavioral_path, stimulus_ls, mice_id, exp_date)\n",
    "# save the speed data to hdf5 files\n",
    "for plane in plane_total_ls:\n",
    "    for stimuli_name in speed_dict.keys():\n",
    "        stimuli_num = 0\n",
    "        for save_subfolder in stimulus_ls:\n",
    "            stimuli_num += 1 \n",
    "            if stimuli_name == save_subfolder[2:]:\n",
    "                sub_folder_name = save_subfolder\n",
    "                # print(speed_dict[stimuli_name].shape)\n",
    "                dict_speed = {'behavior': {'speed': speed_dict[stimuli_name]}} #the 'behavior' is the group name, the 'speed' is the dataset name\n",
    "                fpath_hdf5 = folder_behavioral_path + \"/results/{}_{}_plane_{}_stimuli_{}.hdf5\".format(mice_id, exp_date, str(plane), str(stimuli_num))\n",
    "                h5py_write(file_path=fpath_hdf5, data_dict=dict_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979400e-a787-4c6b-8540-70fbcf802e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_behavioral_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc074c2-ad1c-4cfb-b9f8-3770980dd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247994e-c46a-4462-a30f-cb7353d2dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze pupil\n",
    "stimuli_name = 'RF4_6' # unfunctional when [stimulus=true] in the pupil_extra function\n",
    "stimulus = True # all movies or not\n",
    "light = False # [light=True] means Infrared is used\n",
    "\n",
    "# (left, right, top, bot) are used to limit the detection window for frames\n",
    "lc = localization_info(left=150,right=480,top=160,bot=380) # C6_20230707 use\n",
    "# lc = localization_info(left=250,right=500,top=180,bot=350) # C6_20230723 use\n",
    "# lc = localization_info(left=210,right=450,top=220,bot=430) # C6_20230705 use\n",
    "pupil_dict = pupil_extra(folder_behavioral_path, lc, mice_id, exp_date, stimulus=stimulus, stimuli=stimuli_name, stimulus_ls=stimulus_ls, light = light)\n",
    "# saving the pupil data to hdf5 files\n",
    "for plane in plane_total_ls:\n",
    "    for stimuli_name in pupil_dict.keys():\n",
    "        stimuli_num = 0\n",
    "        for save_subfolder in stimulus_ls:\n",
    "            stimuli_num += 1 \n",
    "            if stimuli_name == save_subfolder[2:]:\n",
    "                sub_folder_name = save_subfolder\n",
    "                # print(pupil_dict[stimuli_name].shape)\n",
    "                dict_speed = {'behavior': pupil_dict[stimuli_name]} #the 'behavior' is the group name, the 'speed' is the dataset name\n",
    "                fpath_hdf5 = folder_behavioral_path + \"/results/{}_{}_plane_{}_stimuli_{}.hdf5\".format(mice_id, exp_date, str(plane), str(stimuli_num))\n",
    "                h5py_write(file_path=fpath_hdf5, data_dict=dict_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6df163-6fbd-4098-8434-8fbc00a99061",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py_read(fpath_hdf5)\n",
    "data['behavior']['speed'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d72332",
   "metadata": {},
   "source": [
    "#### 4.1 Align the hehavior data to calcium signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a30d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_utils import h5py_delete, h5py_read, h5py_write\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "for stim in range(1, 10):\n",
    "    # read the behavior data\n",
    "    fpath_hdf5 = folder_behavioral_path + \"/results/{}_{}_stimuli_{}.hdf5\".format(mice_id, exp_date, stim)\n",
    "    print(fpath_hdf5)\n",
    "    temp = h5py_read(fpath_hdf5, group_read='behavior',dataset_read='all')\n",
    "    pupil_x = temp['behavior']['Pupil_X']\n",
    "    pupil_y = temp['behavior']['Pupil_Y']\n",
    "    pupil_area = temp['behavior']['Pupil_area']\n",
    "    speed = temp['behavior']['speed']\n",
    "    time_arduino = np.arange(len(speed)) * 0.10014 # use 0.10014 to aligen the trigger signals recorded from \n",
    "\n",
    "    # read the rois data\n",
    "    h5_name = '{}_{}_plane_{}_stimuli_{}.hdf5'.format(mice_id, exp_date, 1, stim)\n",
    "    h5_path = os.path.join(folder_2p_path, 'Plane{}'.format(1), 'Analysis', stimulus_ls[stim-1], h5_name)\n",
    "    # print(h5_path)\n",
    "    temp = h5py_read(h5_path, group_read='rois',dataset_read='all')\n",
    "    n_rois = len(temp['rois']['rois_area'])\n",
    "    rois_delta_fluor = temp['rois']['rois_delta_fluor']\n",
    "    n_frames = rois_delta_fluor.shape[1]\n",
    "    time_resample = np.arange(n_frames) * 0.100411522633745\n",
    "\n",
    "    # resampling the behavior data\n",
    "    pupil_area_resample = np.interp(time_resample, time_arduino[0:len(pupil_area)], pupil_area)\n",
    "    pupil_x_resample = np.interp(time_resample, time_arduino[0:len(pupil_x)], pupil_x)\n",
    "    pupil_y_resample = np.interp(time_resample, time_arduino[0:len(pupil_y)], pupil_y)\n",
    "    speed_resample = np.interp(time_resample, time_arduino, speed)\n",
    "    pupil_area_resample = pupil_area_resample.reshape((1, n_frames))\n",
    "    pupil_x_resample = pupil_x_resample.reshape((1, n_frames))\n",
    "    pupil_y_resample = pupil_y_resample.reshape((1, n_frames))\n",
    "    speed_resample = speed_resample.reshape((1, n_frames))\n",
    "    behavior_resample = np.vstack((pupil_area_resample, pupil_x_resample, pupil_y_resample, speed_resample))\n",
    "\n",
    "    for plane in plane_total_ls:\n",
    "        h5_name = '{}_{}_plane_{}_stimuli_{}.hdf5'.format(mice_id, exp_date, plane, stim)\n",
    "        h5_path = os.path.join(folder_2p_path, 'Plane{}'.format(plane), 'Analysis', stimulus_ls[stim-1], h5_name)\n",
    "        print(h5_path)\n",
    "        temp = h5py_read(h5_path, group_read='rois',dataset_read='all')\n",
    "        n_rois = len(temp['rois']['rois_area'])\n",
    "        rois_delta_fluor = temp['rois']['rois_delta_fluor']\n",
    "        # print(rois_delta_fluor.shape)\n",
    "        rois_delta_fluor = np.append(rois_delta_fluor[0:n_rois], behavior_resample, axis=0)\n",
    "        # print(rois_delta_fluor.shape)\n",
    "        h5py_delete(file_path=h5_path, group_path='rois/rois_delta_fluor')\n",
    "        h5py_write(file_path=h5_path, data_dict={'rois': {'rois_delta_fluor':rois_delta_fluor}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to test the align of trigger signals\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# stim = 6\n",
    "# fpath = '{}/raw/{}-{}-{}_{}.txt'.format(folder_behavioral_path, exp_date[:4], exp_date[4:6], exp_date[-2:], stimulus_ls[stim-1][2:])\n",
    "# print(fpath)\n",
    "# speed_total_df = pd.read_table(fpath,sep='\\s+')\n",
    "# trigger_arduino = np.array(speed_total_df.iloc[:, 2].values.tolist())\n",
    "# print(trigger_arduino[0])\n",
    "# time_arduino = np.arange(len(trigger_arduino)) * 0.100132 # use 0.100132 to aligen the trigger signals recorded from different computers\n",
    "\n",
    "# stim_folder = glob.glob(folder_2p_path + '/raw/TSeries-*' + '{}'.format(stim))[0]\n",
    "# trigger_file = glob.glob(stim_folder + '/*.csv')[0]\n",
    "# print(trigger_file)\n",
    "# trigger_df = pd.read_csv(trigger_file)\n",
    "# time_s = trigger_df['Time(ms)'].to_numpy() * 0.001 # time: ms to s\n",
    "# trigger_signal = trigger_df[' Input 1'].to_numpy()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(time_arduino, trigger_arduino)\n",
    "# ax.plot(time_s, trigger_signal)\n",
    "# ax.set_xlim(480, 490)\n",
    "\n",
    "# # test resampled data\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(time_arduino[0:len(pupil_area)], pupil_area)\n",
    "# ax.plot(time_resample, pupil_area_resample[0,:])\n",
    "# ax.set_xlim(100, 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89f7ed-d853-48fc-8453-e2d6e22e60ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 5: sort calcium signals to visual stimuli and analyze neuronal responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad5924-0536-4e00-9b86-ce42f3872508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_utils import *\n",
    "from other_utils import *\n",
    "import glob,datetime\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ca7f5-5984-47b0-b39b-81dd63b6eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plane in plane_total_ls:\n",
    "    stimuli_list = list(range(1,stimulus_num+1))\n",
    "    # stimuli_list = [1,2,3,4,5,9]\n",
    "    plot_results = np.zeros(stimulus_num,dtype='bool')\n",
    "    # plot_results[[0,1]] = True\n",
    "    for i,stim_num in enumerate(stimuli_list):\n",
    "        h5_folder =  folder_2p_path + '/plane' + str(plane) + '/analysis/' + stimulus_ls[stim_num-1]\n",
    "        h5_path = glob.glob(h5_folder+'/*.hdf5')[0]\n",
    "        print(h5_path)\n",
    "        if i==0:\n",
    "            h5_data = h5py_read(h5_path)\n",
    "            rois = {'pos':h5_data['rois']['rois_pos'],\n",
    "                    'area':h5_data['rois']['rois_area']}\n",
    "        results = pre_process(h5_path)\n",
    "        match stim_num:\n",
    "            case 1:\n",
    "                results['visual_center'] = np.array([95,25])\n",
    "                results['size'] = 5\n",
    "                results_rf = analysis_rf(results,plot_results[stim_num-1])\n",
    "            case 2:\n",
    "                results_mb = analysis_mb(results,para,plot_results[stim_num-1])\n",
    "            case 3:\n",
    "                results_sg_1 = analysis_sg1(results,plot_results[stim_num-1])\n",
    "            case 4:\n",
    "                results['n_stim'] = 12\n",
    "                results_sg_2 = analysis_sg2(results,plot_results[stim_num-1])\n",
    "            case 5:\n",
    "                results_sg_3 = analysis_sg3(results,plot_results[stim_num-1])\n",
    "            case 6:\n",
    "                results_smd_1 = analysis_smd1(results,plot_results[stim_num-1])\n",
    "            case 7:\n",
    "                results_smd_2 = analysis_smd2(results,plot_results[stim_num-1])\n",
    "            case 8:\n",
    "                results_smd_3 = analysis_smd3(results,plot_results[stim_num-1])\n",
    "            case 9:\n",
    "                results_md = analysis_md(results,plot_results[stim_num-1])\n",
    "        print('plane'+str(plane)+'stim'+str(stim_num)+' is done!')    \n",
    "    results_dict = {'results_rf':results_rf,\n",
    "               'results_mb':results_mb,\n",
    "               'results_sg_1':results_sg_1,\n",
    "               'results_sg_2':results_sg_2,\n",
    "               'results_sg_3':results_sg_3,\n",
    "               'results_smd_1':results_smd_1,\n",
    "               'results_smd_2':results_smd_2,\n",
    "               'results_smd_3':results_smd_3,\n",
    "               'results_md':results_md}\n",
    "    results_path = folder_2p_path + '/plane' + str(plane) + '/analysis/results.hdf5'    \n",
    "    h5py_write(results_path,results_dict,overwrite=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756660c6-f0aa-4118-8410-a11ba8bf7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09515253-acd9-48e1-89fe-c223143998d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
