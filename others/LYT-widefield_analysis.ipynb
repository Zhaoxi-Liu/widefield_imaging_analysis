{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from __future__ import print_function\n",
    "# from __future__ import division\n",
    "\n",
    "import os\n",
    "from tifffile import imread, imsave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import cv2\n",
    "#import sima\n",
    "#import sima.motion\n",
    "#import sima.segment\n",
    "import scipy\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import h5py\n",
    "import time\n",
    "import scipy.io\n",
    "import shutil\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "magnitude = 105/50\n",
    "sensor_size = np.asarray([11.264,5.984])*1000 #sensor size of camera, in um\n",
    "image_max_size = sensor_size/magnitude # in um\n",
    "pixel_max_size = np.asarray([2040,1086])# in pixel \n",
    "size_per_pixel = image_max_size/pixel_max_size# in um/pixel\n",
    "size_per_pixel_single = np.mean(size_per_pixel)# in um/pixel\n",
    "size_per_pixel_down_sample = 10 # in um, the desired spational resolution for down sampling\n",
    "reso_pixel_down_sample = int(np.ceil(size_per_pixel_down_sample/size_per_pixel_single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_batch = [\n",
    "#                 'L:/Wild_type/AQ1/20190520/md_1/processed/all_image_down_sampled_1_rig.tif',  \n",
    "#                 'L:/Wild_type/AQ3/20190523/md_1/processed/all_image_down_sampled_1_rig.tif',            \n",
    "#                 'L:/Wild_type/AQ4/20190524/md_1/processed/all_image_down_sampled_1_rig.tif',\n",
    "#                 ]\n",
    "# path_save = 'C:/Users/yatang/Google Drive/optic imaging/'\n",
    "# file_save = ['AQ1','AQ3','AQ4']\n",
    "# for i,path in enumerate(path_batch):\n",
    "#     image = imread(path)\n",
    "#     image_save = image[:200,:,:]\n",
    "#     imsave(path_save+file_save[i]+'.tif',image_save,imagej=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntpath.abspath(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2int(x):\n",
    "    filename = os.path.splitext(x)[0]\n",
    "    idx_last = [m.start() for m in re.finditer('_', filename)][-1]\n",
    "    return int(filename[idx_last+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get started\n",
    "path_0_batch = [\n",
    "#                 'L:/Wild_type/AO2/20181031/',  \n",
    "#                 'L:/Wild_type/AO1/20181101/',            \n",
    "#                 'L:/Wild_type/AO1/20181105/',\n",
    "#                 'L:/Wild_type/AO3/20181102/',\n",
    "#                 'L:/Wild_type/AO3/20181106/'\n",
    "#                 'L:/Wild_type/AO1/20181207/'\n",
    "#                 'L:/Wild_type/AP1/20181210/'\n",
    "#                 'L:/Wild_type/AP1/20181212/'\n",
    "#                 'L:/Wild_type/AP3/20181214_left_eye/',\n",
    "#                 'L:/Wild_type/AP3/20181214_right_eye/'\n",
    "#                 'L:/Wild_type/AO1/20190122/',\n",
    "#                 'L:/Wild_type/AO1/20190204/',\n",
    "#                 'L:/Wild_type/AJ1/20190116/',\n",
    "#                 'L:/Wild_type/AJ2/20190111/',\n",
    "#                 'L:/Wild_type/AJ3/20190116/',\n",
    "#                 'L:/Wild_type/AK1/20190116/',\n",
    "#                 'L:/Wild_type/AK2/20190116/',\n",
    "#                 'L:/Wild_type/AQ1/20190111/',\n",
    "#                 'L:/Wild_type/AQ1/20190207/',\n",
    "#                 'L:/Wild_type/AQ2/20190116/',\n",
    "#                 'L:/Wild_type/AQ2/20190208/',\n",
    "#                 'L:/Wild_type/AP1/20190214/',\n",
    "#                 'L:/Wild_type/AP3/20190215/',\n",
    "#                 'L:/Wild_type/AQ3/20190211/',\n",
    "#                 'L:/Wild_type/AQ4/20190212/',\n",
    "#                 'L:/Wild_type/AO1/20190122/',\n",
    "    \n",
    "#                 'L:/Wild_type/AL1/20190412/',\n",
    "#                 'L:/Wild_type/AO1/20190417/',\n",
    "#                 'L:/Wild_type/AP1/20190418/',\n",
    "#                 'L:/Wild_type/AP3/20190418/',\n",
    "#                 'L:/Wild_type/AM1/20190419/',\n",
    "#                 'L:/Wild_type/AQ2/20190419/',\n",
    "#                 'L:/Wild_type/AR1/20190423/',\n",
    "#                 'L:/Wild_type/AQ1/20190520/',\n",
    "#                 'L:/Wild_type/AQ3/20190523/',\n",
    "#                 'L:/Wild_type/AQ4/20190524/',\n",
    "    \n",
    "    \n",
    "    'L:/Wild_type/AQ1/20190829/',\n",
    "    'L:/Wild_type/AQ3/20190829/',\n",
    "    'L:/Wild_type/AQ3/20190829_2/',\n",
    "    'L:/Wild_type/AQ4/20190830/',\n",
    "\n",
    "    \n",
    "               ]\n",
    "\n",
    "path_1 = [\n",
    "#             'md_0/',\n",
    "#             'mb_0/',\n",
    "#             'fg_0/',\n",
    "#             'md_1/',\n",
    "#             'mb_1/',\n",
    "#             'fg_1/',\n",
    "#             'md_2/',\n",
    "#             'mb_2/',\n",
    "#             'fg_2/',\n",
    "#             'loom_tile/',\n",
    "#             'optic_flow/'ï¼Œ\n",
    "            'retino_reso/'\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample the images\n",
    "for path_0 in path_0_batch:\n",
    "    print(path_0_batch)\n",
    "#     print(path_0) \n",
    "    path_all = []\n",
    "    for path in path_1:\n",
    "        if os.path.exists(path_0+path):\n",
    "            path_all.append(path_0+path)\n",
    "\n",
    "    for path in path_all:\n",
    "        if not os.path.exists(path+'raw/'):\n",
    "            os.mkdir(path+'raw/')\n",
    "\n",
    "    for path in path_all:\n",
    "        files = os.listdir(path)\n",
    "        for f in files:\n",
    "            if os.path.isfile(path+f):\n",
    "                shutil.move(path+f, path+'raw/'+f)\n",
    "\n",
    "    for path in path_all:\n",
    "        tiffiles_raw = [os.path.join(root, name)\n",
    "                     for root, dirs, files in os.walk(path+'raw/')\n",
    "                     for name in files\n",
    "                     if name.endswith((\".tif\", \".tiff\"))]\n",
    "        tiffiles = sorted(tiffiles_raw,key = file2int)\n",
    "        num_image = len(tiffiles)\n",
    "        image = imread(tiffiles[0])\n",
    "        blur = cv2.blur(image,(reso_pixel_down_sample*2,reso_pixel_down_sample*2))\n",
    "        image_down_sampled = blur[::reso_pixel_down_sample,::reso_pixel_down_sample]\n",
    "        [row,col]=np.shape(image_down_sampled)\n",
    "    #     row_del_start = 20\n",
    "    #     row_del_end = -20\n",
    "    #     col_del_start = 30\n",
    "    #     col_del_end = -30\n",
    "    #     image_all = np.empty([num_image,row-np.int(np.abs(row_del_start)+np.abs(row_del_end)),col-np.int(np.abs(col_del_start)+np.abs(col_del_end))], dtype='uint16')\n",
    "        image_all = np.empty([num_image,row,col], dtype='uint16')\n",
    "        # input and down-sample images\n",
    "        print('loading and down-sampling images')\n",
    "        i=0\n",
    "        for tiff in log_progress(tiffiles):\n",
    "            image = imread(tiff)\n",
    "            image_blur = cv2.blur(image,(reso_pixel_down_sample*2,reso_pixel_down_sample*2))\n",
    "            image_down_sampled = image_blur[::reso_pixel_down_sample,::reso_pixel_down_sample]\n",
    "    #         image_all[i,:,:] = image_down_sampled[row_del_start:row_del_end,col_del_start:col_del_end]\n",
    "            image_all[i,:,:] = image_down_sampled\n",
    "        #    print(i,'of',num_image)\n",
    "            i+=1\n",
    "\n",
    "        path_save = path+'processed/'\n",
    "        if not os.path.exists(os.path.dirname(path_save)):\n",
    "            os.makedirs(path_save)\n",
    "        if ('loom' in path) or ('md' in path) or ('optic_flow' in path):\n",
    "            [num_image,_,_] = image_all.shape\n",
    "            num_half = long(num_image/2)\n",
    "            image_1 = image_all[:num_half,:,:]\n",
    "            imsave(path_save+'all_image_down_sampled_1.tif',image_1,imagej=True)\n",
    "            image_2 = image_all[num_half:,:,:]\n",
    "            imsave(path_save+'all_image_down_sampled_2.tif',image_2,imagej=True)\n",
    "        else:\n",
    "            imsave(path_save+'all_image_down_sampled.tif',image_all,imagej=True)\n",
    "        print('done:'+path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate or cut images if necessary\n",
    "# important: only run once!!!\n",
    "for path_0 in path_0_batch:\n",
    "    print(path_0_batch)\n",
    "    path_all = []\n",
    "    for path in path_1:\n",
    "        if os.path.exists(path_0+path):\n",
    "            path_all.append(path_0+path)\n",
    "       \n",
    "    flag = True    \n",
    "    for path in log_progress(path_all):\n",
    "        tiffiles = [os.path.join(root, name)\n",
    "                     for root, dirs, files in os.walk(path+'processed/')\n",
    "                     for name in files\n",
    "                     if name.endswith((\".tif\", \".tiff\"))]\n",
    "        for i,tif in enumerate(tiffiles):\n",
    "            image = imread(tif)\n",
    "            [n_frame, n_row, n_col] = np.shape(image)\n",
    "#             image_temp = np.rot90(image[0,:155,:300])\n",
    "#             image_temp = np.flip(image[0,:,:],1)\n",
    "            image_temp = np.rot90(image[0,:,:],2)\n",
    "            [n_row_new, n_col_new] = np.shape(image_temp)\n",
    "            image_new = np.empty([n_frame,n_row_new, n_col_new], dtype='uint16')\n",
    "            for j in range(n_frame):\n",
    "#                 image_new[j,:,:] = np.rot90(image[j,:155,:300])\n",
    "#                 image_new[j,:,:] = np.flip(image[j,:,:],1)\n",
    "#                 image_new[j,:,:] = np.rot90(np.flip(image[j,:,:],1),2)\n",
    "                image_new[j,:,:] = np.rot90(image[j,:,:],2)\n",
    "            imsave(tif,image_new,imagej=True)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run motion correction using MATLAB\n",
    "#load motion-corrected images \n",
    "# save roi-based files to .flr file to be read by MATALB\n",
    "\n",
    "for path_0 in path_0_batch:\n",
    "    print(path_0_batch)\n",
    "    path_all = []\n",
    "    for path in path_1:\n",
    "        if os.path.exists(path_0+path):\n",
    "            path_all.append(path_0+path)\n",
    "       \n",
    "    flag = True    \n",
    "    for path in log_progress(path_all):\n",
    "        tiffiles = [os.path.join(root, name)\n",
    "                     for root, dirs, files in os.walk(path+'processed/')\n",
    "                     for name in files\n",
    "                     if name.endswith((\"rig.tif\", \"rig.tiff\"))]\n",
    "        \n",
    "        if np.size(tiffiles)==0:\n",
    "            continue\n",
    "            \n",
    "        for i,tif in enumerate(tiffiles):\n",
    "            image_mc = imread(tif)\n",
    "            if i==0:\n",
    "                image_all_mc = image_mc\n",
    "            else:\n",
    "                image_all_mc = np.concatenate((image_all_mc, image_mc), axis=0)\n",
    "\n",
    "        [n_frame, n_row, n_col] = np.shape(image_all_mc)\n",
    "        datapara = np.zeros(100)\n",
    "        datapara[0] = int(n_row*n_col) #'numofrois'        \n",
    "        datapara[1] = 10;#'samplingrate' unit Hz\n",
    "        datapara[2] = 1/datapara[1];#'frametime'unit sec\n",
    "        datapara[3] = n_col;#'Xres'\n",
    "        datapara[4] = n_row;#'Yres'\n",
    "        datapara[5] = datapara[3]*size_per_pixel_down_sample #'Xscale' \n",
    "        datapara[6] = datapara[4]*size_per_pixel_down_sample #'Yscale'\n",
    "        if flag:\n",
    "            x_reso = n_col\n",
    "            y_reso = n_row\n",
    "            x_scale = datapara[5]\n",
    "            y_scale = datapara[6]\n",
    "            scipy.io.savemat(path_0+'image_info.mat',mdict={'x_reso': x_reso,'y_reso':y_reso,\n",
    "                                                            'x_scale':x_scale,'y_scale':y_scale})\n",
    "            flag = False\n",
    "\n",
    "        datapara[7] = 4 #'procedure'\n",
    "        datapara[8] = 12 #'numofstim'\n",
    "        if path[-5:-3:] == 'fg':\n",
    "            datapara[9] = 5 #'repetition'\n",
    "        else:\n",
    "            datapara[9] = 10 #'repetition'\n",
    "        datapara[10]= n_frame #'numofframes'\n",
    "        datapara[11] = int(n_frame/(datapara[8]*datapara[9])) #'frames_per_trig'\n",
    "        trig = np.zeros(n_frame)\n",
    "        if path[-14:-3] == '20180924/mb':\n",
    "            temp = np.where(np.mod(range(470*12*10),6)==0)\n",
    "            trig_idx = [0]\n",
    "            for i in range(1,9400-2):\n",
    "                if np.mod(temp[0][i],470)>np.mod(temp[0][i+1],470):\n",
    "                    trig_idx.append(i)\n",
    "            trig[trig_idx] = 1\n",
    "        else:\n",
    "            trig[::int(datapara[11])]=1\n",
    "        print('the number of trig is:'+str(np.size(np.where(trig==1))))    \n",
    "        path_h5 = path+'processed/'+path[path.index('201')::].replace('/','_')[:-1:]+'.h5'\n",
    "        hf = h5py.File(path_h5, 'w')\n",
    "        hf.create_dataset('datapara', data=datapara)\n",
    "        hf.create_dataset('data', data=image_all_mc)\n",
    "        hf.create_dataset('trig', data=trig)\n",
    "        hf.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_all_mc[1,:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_all_mc[0,:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image[1,:,:] = np.rot90(np.flip(image[1,:,:],1),2)\n",
    "# image_new[j,:,:] = np.rot90(image[j,:,:],2)\n",
    "plt.imshow(image,cmap='gray',aspect='equal')   \n",
    "plt.show()\n",
    "plt.imshow(np.rot90(image,2),cmap='gray',aspect='equal')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_0_batch = [\n",
    "                'L:/Wild_type/AO1/20181101/'            \n",
    "                'L:/Wild_type/AO1/20181105/',\n",
    "                'L:/Wild_type/AO3/20181102/',\n",
    "                'L:/Wild_type/AO3/20181106/'\n",
    "               ]\n",
    "for path_0 in path_0_batch:\n",
    "    path_1 = [\n",
    "                'md_0/',\n",
    "                'md_1/',\n",
    "                'md_2/',\n",
    "                'mb_0/',\n",
    "                'mb_1/',\n",
    "                'mb_2/',\n",
    "                'fg_0/',\n",
    "                'fg_1/',\n",
    "                'fg_2/',\n",
    "                'loom_tile/',\n",
    "               ]\n",
    "\n",
    "    path_all = []\n",
    "    for path in path_1:\n",
    "        path_all.append(path_0+path)\n",
    "        \n",
    "    flag = True    \n",
    "    for path in log_progress(path_all):\n",
    "        tiffiles = [os.path.join(root, name)\n",
    "                     for root, dirs, files in os.walk(path+'processed/')\n",
    "                     for name in files\n",
    "                     if name.endswith((\"rig.tif\", \"rig.tiff\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reso = n_col\n",
    "y_reso = n_row\n",
    "x_scale = datapara[5]\n",
    "y_scale = datapara[6]\n",
    "scipy.io.savemat(path_0+'image_info.mat',mdict={'x_reso': x_reso,'y_reso':y_reso,\n",
    "                                                'x_scale':x_scale,'y_scale':y_scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run motion correction\n",
    "print('running motion correction')\n",
    "\n",
    "data_temp=np.expand_dims(np.expand_dims(image_all,axis=1),axis=4)\n",
    "sequences = [sima.Sequence.create('ndarray', data_temp)]\n",
    "dataset_path = path+'processed/all_image_PlaneTranslation2D.sima'\n",
    "correction_approach_PlaneTranslation2D = sima.motion.PlaneTranslation2D(max_displacement = [30, 30])   \n",
    "dataset = correction_approach_PlaneTranslation2D.correct(sequences, dataset_path, trim_criterion=0.95)\n",
    "print(\"done motion correction. Saving...\")\n",
    "# Generate the output filenames with Python list comprehensions.\n",
    "size_limit = 4e9\n",
    "if image_all.nbytes>size_limit:\n",
    "#    output_filenames = [[[images_all_file.replace('.tif', '_corrected_PlaneTranslation2D.tif')]]]\n",
    "    output_filenames_hdf5 = [[[path+'processed/all_image_corrected_PlaneTranslation2D.h5']]]\n",
    "    # The resulting filenames are printed for clarification.\n",
    "    print(\"Output filenames:\\n\")\n",
    "    print(output_filenames_hdf5)\n",
    "\n",
    "    # Export the corrected frames for a presentation.\n",
    "#    dataset.export_frames(output_filenames, fill_gaps=True)\n",
    "    dataset.export_frames(output_filenames_hdf5, fmt='HDF5', fill_gaps=True)\n",
    "    print(\"\\nDone exporting!\")\n",
    "\n",
    "\n",
    "else:\n",
    "    output_filenames =  [[[path+'processed/all_image_corrected_PlaneTranslation2D.tif']]]\n",
    "#        output_filenames_hdf5 = [images_all_file.replace('.tif', '_corrected_PlaneTranslation2D.h5')]\n",
    "    # The resulting filenames are printed for clarification.\n",
    "    print(\"Output filenames:\\n\")\n",
    "    print(output_filenames)\n",
    "\n",
    "    # Export the corrected frames for a presentation.\n",
    "    dataset.export_frames(output_filenames, fill_gaps=True)\n",
    "#        dataset.export_frames(output_filenames_hdf5, fmt='HDF5', fill_gaps=True)\n",
    "    print(\"\\nDone exporting!\")             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
