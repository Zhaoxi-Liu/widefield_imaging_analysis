{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import rois_to_pixels\n",
    "from analysis import dff_images\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from sklearn import decomposition\n",
    "from skimage.transform import downscale_local_mean\n",
    "from tifffile import imwrite\n",
    "from visualization import plot_traces\n",
    "from visualization import show_array_images\n",
    "from visualization import show_images\n",
    "from visualization import show_one_image\n",
    "from wfield.io import mmap_dat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/wrx/Data_WF/WF_WRX/'\n",
    "# root_path = '/home/wrx/Data_DOM/Widefield'\n",
    "mouse_id = 'Q39'\n",
    "date = '20240829'\n",
    "treatment = 'saline'\n",
    "\n",
    "treatment_folder = os.path.join(root_path, mouse_id, f'{date}_{treatment}')\n",
    "print(treatment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bin_path\n",
    "stim_folders = [f for f in glob(os.path.join(treatment_folder, '*')) if \\\n",
    "    os.path.isdir(f)]\n",
    "pprint(stim_folders)\n",
    "wfield_folder = glob(os.path.join(stim_folders[0], 'process', '*wfield'))[0]\n",
    "print(os.path.exists(wfield_folder))\n",
    "bin_path = glob(os.path.join(wfield_folder, '*.bin'))[0]\n",
    "print(bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the bin file\n",
    "data_raw = mmap_dat(bin_path)\n",
    "print(data_raw.shape)\n",
    "\n",
    "# to verify the channel order by showing the first frame\n",
    "show_images([data_raw[0][0], data_raw[0][1]], idential_colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0, 300\n",
    "data_preview = data_raw[start:end, 0, :, :]\n",
    "print('Shape of data_preview:', data_preview.shape)\n",
    "data_std = np.std(data_preview, axis=0)\n",
    "show_one_image(data_std, cmap='hot', colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = os.path.join(wfield_folder, 'reference.tif')\n",
    "if os.path.exists(reference_path):\n",
    "    print('Reference image already exists, skipping saving.')\n",
    "else:\n",
    "    imwrite(reference_path, data_mean.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the reigion of not interest as 0 to reduce the noise\n",
    "mask_path = os.path.join(wfield_folder, 'mask.zip')\n",
    "pixels = rois_to_pixels(mask_path, data_std.shape)\n",
    "print(pixels.shape)\n",
    "\n",
    "data_masked = data_raw[:, 0, :, :].copy()\n",
    "data_masked[:, pixels[1, :], pixels[0, :]] = 0\n",
    "show_one_image(data_masked[0], cmap='hot', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downsample = downscale_local_mean(data_masked, (1, 4, 4))\n",
    "print('Shape of data_downsample:', data_downsample.shape)\n",
    "_data = data_downsample.reshape(data_downsample.shape[0], -1)\n",
    "print('Shape of _data:', _data.shape)\n",
    "show_one_image(data_downsample[0], cmap='hot', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Delta F / F$ of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the dff of each pixel in the image\n",
    "images_dff = dff_images(data_downsample)\n",
    "print('Shape of images_dff:', images_dff.shape)\n",
    "# replace the nans with 0\n",
    "images_dff[np.isnan(images_dff)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the dff image of selected frame\n",
    "index = 200\n",
    "show_one_image(images_dff[index], cmap='hot', colorbar=True)\n",
    "\n",
    "# plot the dff trace of selected pixels\n",
    "x, y = 70, 50\n",
    "plot_traces(images_dff[:, y, x:x+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images_dff.reshape(images_dff.shape[0], -1)\n",
    "print('Shape of X:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "whiten = True\n",
    "svd_solver = 'randomized'\n",
    "random_state = 42\n",
    "pca_estimator = decomposition.PCA(n_components=n_components, whiten=whiten,\n",
    "    svd_solver=svd_solver, random_state=random_state)\n",
    "# X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "pca_estimator.fit(X)\n",
    "\n",
    "print('Explained variance ratio:',\n",
    "    pca_estimator.explained_variance_ratio_.sum())\n",
    "\n",
    "pac_components = pca_estimator.components_\n",
    "print('Shape of pac_components:', pac_components.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sum of explained variance ratio\n",
    "explained_variance_sum = np.cumsum(pca_estimator.explained_variance_ratio_)\n",
    "title = 'Explained Variance Ratio {:.5f}'.format(explained_variance_sum[-1])\n",
    "plot_traces(explained_variance_sum[:, np.newaxis], figsize=(5, 5),\n",
    "    title=title, xlabel='Number of Components',\n",
    "    ylabel='Explained Variance Ratio', hlines=[explained_variance_sum[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the components\n",
    "n_show = 10\n",
    "title = f'{mouse_id}_{date}_{treatment} PCA n_components={n_components}'\n",
    "show_array_images(pac_components[: n_show].reshape(n_show,\n",
    "    data_downsample.shape[1], data_downsample.shape[2]),\n",
    "    cmap='bwr', title=title, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timecourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timecourse = pca_estimator.transform(X)\n",
    "print('Shape of timecourse:', timecourse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'{mouse_id}_{date}_{treatment} PCA Timecourse'\n",
    "plot_dff(timecourse[:, :n_show], step=6, figsize=(15, 10), data_rate=10, \n",
    "    title=title, xlabel='Time (s)', ylabel='PCA Timecourse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inverse = pca_estimator.inverse_transform(pca_estimator.transform(X))\n",
    "print('Shape of data_inverse:', data_inverse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reconstruct = data_inverse.reshape(data_downsample.shape)\n",
    "print('Shape of data_reconstruct:', data_reconstruct.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA of custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_x(X,centralize=True):\n",
    "    \"\"\"\n",
    "    SVD approach for principal components analysis\n",
    "    PV: principal axis \n",
    "    PC: principal components\n",
    "    lambda: variance explained\"\"\"\n",
    "    [n, p] = np.shape(X)                \n",
    "    X_0 = np.zeros((n,p))\n",
    "    if centralize:\n",
    "        for i in range(p):\n",
    "            X_0[:,i] =  X[:,i]-np.mean(X[:,i])\n",
    "    else:\n",
    "        X_0 = X\n",
    "    [U,S,Vt] = np.linalg.svd(X_0)\n",
    "    V = Vt.T\n",
    "    lamda = np.square(S)/(n-1)\n",
    "    lamda = lamda/np.sum(lamda)\n",
    "    PV = V\n",
    "    PC = X_0@PV #principal components\n",
    "    return PV, lamda, PC, Vt, S\n",
    "\n",
    "X = images_dff.reshape(images_dff.shape[0], -1)\n",
    "print('Shape of X:', X.shape)\n",
    "PV, lamda, PC, Vt, S = pca_x(X, centralize=True)\n",
    "print('Shape of PV:', PV.shape)\n",
    "print('Shape of lamda:', lamda.shape)\n",
    "print('Shape of PC:', PC.shape)\n",
    "print('Shape of Vt:', Vt.shape)\n",
    "print('Shape of S:', S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = PV[:, :n_show].T\n",
    "print('Shape of pca_components:', pca_components.shape)\n",
    "pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_index = pca_components.mean(axis=1) < 0\n",
    "pca_components[_index, :] = -pca_components[_index, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_show = 10\n",
    "show_array_images(pca_components.reshape(n_show,\n",
    "    data_downsample.shape[1], data_downsample.shape[2]),\n",
    "    cmap='bwr', title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 40\n",
    "explained_variance_sum = np.cumsum(lamda[:n_components])\n",
    "\n",
    "title = 'Explained variance sum: {:.6}'.format(\n",
    "    explained_variance_sum[-1])\n",
    "plot_traces(explained_variance_sum[:, np.newaxis], figsize=(5, 5),\n",
    "    title=title, xlabel='Number of Components',\n",
    "    ylabel='Explained Variance Ratio', hlines=[explained_variance_sum[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(X, variance_explained,plot_flag=True):\n",
    "    if plot_flag:\n",
    "        imshow_X(X,'original X')\n",
    "    n_cells, n_samples = np.shape(X)\n",
    "    pv, lamda, pc = pca_x(X,centralize=True)\n",
    "    lamda_cumsum = np.cumsum(lamda)\n",
    "    if plot_flag:\n",
    "        fig, axes = plt.subplots(2, 1, sharex=True, figsize=(fig_width,fig_height/3))\n",
    "        axes[0].plot(lamda[:100],marker='o')\n",
    "        axes[1].plot(lamda_cumsum[:100],marker='o')\n",
    "        axes[1].set_ylabel('variance explained')\n",
    "        axes[1].set_xlabel('number of PCs')\n",
    "\n",
    "    k = np.where(lamda_cumsum>variance_explained)[0][0]+1\n",
    "    pc_k = pc[:,:k]\n",
    "    pv_k = pv[:,:k]\n",
    "  \n",
    "    lamda_array = np.ones([n_samples,1])@np.reshape(lamda,(1,-1))\n",
    "    pv_scaled = np.multiply(lamda_array,pv)\n",
    "    \n",
    "    if plot_flag:\n",
    "        fig, axes = plt.subplots(2, 1, sharex=True, figsize=(fig_width,np.min([k/4,fig_height])))\n",
    "        sns.heatmap(pv_scaled[:,:k].T,cmap='viridis',xticklabels=False, yticklabels=False, ax=axes[0])\n",
    "        axes[0].set_title(str(k)+' principal vectors,'+ str(variance_explained*100) + '% of vraiance explained')\n",
    "        sns.heatmap(pv_k.T,cmap='viridis',xticklabels=False, yticklabels=False, ax=axes[1])\n",
    "        \n",
    "        # plot principal components \n",
    "        imshow_X(pc[:,:k],'principal components',sampling_rate=1)\n",
    "        # visualize the first 2 PCs\n",
    "        plt.figure(figsize=(fig_width,fig_height/3))\n",
    "        plt.scatter(pc[:,0],pc[:,1],s=20,facecolors='none',edgecolors='k',marker='^',alpha=0.3)\n",
    "        plt.xlabel('PC 1')\n",
    "        plt.ylabel('PC 2')\n",
    "    # reconstruct X with PCs that explain variance_explained of variance\n",
    "    k =np.where(lamda_cumsum>variance_explained)[0][0]+1\n",
    "    X_0_new = pc[:,:k]@pv[:,:k].T\n",
    "    X_new = np.zeros_like(X)\n",
    "    for i in range(n_samples):\n",
    "        X_new[:,i] =  X_0_new[:,i]+np.mean(X[:,i])\n",
    "    if plot_flag:\n",
    "        imshow_X(X_new,'reconstructed X with '+str(k)+' PCs')\n",
    "    return k, pc_k, pv_scaled, X_new, lamda_cumsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "max_iter = 1000\n",
    "random_state = 42\n",
    "ica_estimator = decomposition.FastICA(n_components=n_components,\n",
    "    max_iter=max_iter, random_state=random_state)\n",
    "\n",
    "# X: array-like of shape (n_samples, n_features)\n",
    "X = images_dff.reshape(images_dff.shape[0], -1)\n",
    "# X = data_inverse\n",
    "print('Shape of X:', X.shape)\n",
    "ica_estimator.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_components = ica_estimator.components_.reshape(n_components, \n",
    "    *data_downsample.shape[1:])\n",
    "print('Shape of reshaped ICA components:', ica_components.shape)\n",
    "\n",
    "# to deal with signs of the components\n",
    "_index = ica_components.mean(axis=(1, 2)) < 0\n",
    "ica_components[_index] = -ica_components[_index]\n",
    "\n",
    "title = f'{mouse_id}_{date}_{treatment} ICA n_components={n_components}'\n",
    "show_array_images(ica_components, n_cols=5, cmap='bwr', title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_masked = ica_components.copy()\n",
    "components_masked[np.abs(ica_components) < 0.3 * ica_components.max()] = 0\n",
    "show_array_images(components_masked, n_cols=5, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_sum = np.sum(components_masked, axis=0)\n",
    "show_one_image(components_sum, cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jadeR for ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./ICA')\n",
    "from jadeR import jadeR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images_dff.reshape(images_dff.shape[0], -1).T\n",
    "# X = data_inverse.T\n",
    "print('Shape of X:', X.shape)\n",
    "\n",
    "n_IC = 10\n",
    "jade_ica = jadeR(X, m=n_IC, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deal with signs of the components\n",
    "signs = np.sign(jade_ica.mean(axis=1))\n",
    "for i in range(jade_ica.shape[0]):\n",
    "    jade_ica[i, :] *= signs[i][0, 0]\n",
    "print(jade_ica.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'{mouse_id}_{date}_{treatment} Jade ICA n_components={n_IC}'\n",
    "show_array_images(np.array(jade_ica).reshape(n_IC,\n",
    "    data_downsample.shape[1], data_downsample.shape[2]),\n",
    "    cmap='bwr', title=title, grid=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wfield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
